# -*- coding: utf-8 -*-
"""NLP ToXic

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xjgDoRpDuU_RukNUV9inze-o_tFKPxCd
"""

# Install required packages
!pip install -q transformers datasets tqdm ipywidgets tensorflow

# Import standard libraries
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

# Use tqdm with notebook integration
from tqdm.notebook import tqdm

# Hugging Face Transformers and Datasets
from transformers import BertTokenizer, BertModel
from datasets import Dataset
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import random
import re

from google.colab import drive
drive.mount('/content/drive')

dataset=pd.read_csv('/content/drive/MyDrive/ML_Project/Datasets/all_data.csv')
df=dataset

# Display shape and columns
print(dataset.shape)
print(dataset.columns)
dataset.head()

# Define bias words and their synonyms
bias_words = {
    "gay": ["homosexual", "queer", "LGBTQ"],
    "homosexual": ["queer", "LGBTQ", "gay"],
    "lesbian": ["gay woman", "queer woman"],
    "bisexual": ["bi", "pansexual"],
    "transgender": ["trans", "gender-diverse"],
    "muslim": ["Islamic", "Muslim person"],
    "male": ["man", "masculine"],
    "female": ["woman", "feminine"],
    "christian": ["Christian believer"],
    "jewish": ["Jew", "person of Jewish faith"],
    "black": ["African descent", "Black person"],
    "white": ["Caucasian", "White person"],
    "asian": ["Asian person", "East Asian"],
    "latino": ["Latinx", "Hispanic"],
    "atheist": ["non-religious"],
    "hindu": ["person of Hindu faith"],
    "buddhist": ["Buddhism follower"],
}

# Compile regex for case-insensitive word matching
pattern = re.compile(r'\b(' + '|'.join(re.escape(word) for word in bias_words) + r')\b', flags=re.IGNORECASE)

# Step 1: Identify rows that contain any bias word
def contains_bias(text):
    if not isinstance(text, str):
        return False
    return bool(pattern.search(text))

# Filter rows that contain bias words
bias_rows = df[df['comment_text'].apply(contains_bias)]

# Select 20% of those rows to modify
num_to_replace = int(len(bias_rows) * 0.20)
replace_indices = random.sample(list(bias_rows.index), num_to_replace)

# Step 2: Replace bias words in selected rows
def replace_with_synonyms(text):
    def replace_match(match):
        word = match.group(0)
        key = word.lower()
        if key in bias_words:
            synonym = random.choice(bias_words[key])
            # Preserve capitalization
            if word.istitle():
                synonym = synonym.capitalize()
            elif word.isupper():
                synonym = synonym.upper()
            return synonym
        return word

    return pattern.sub(replace_match, text)

# Apply replacements only to the selected 20% rows
for idx in replace_indices:
    df.at[idx, 'comment_text'] = replace_with_synonyms(df.at[idx, 'comment_text'])

# Save to new CSV if needed
df.to_csv("/content/drive/MyDrive/ML_Project/Datasets/updated_comments_20percent.csv", index=False)
dataset=df

# Count missing values per column (NaN or None)
missing_values = dataset.isnull().sum()

# Plot
if not missing_values.empty:
    plt.figure(figsize=(10, 6))
    missing_values.plot(kind='bar', color='salmon')
    plt.title('Missing Values per Column')
    plt.xlabel('Column')
    plt.ylabel('Number of Missing Values')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.show()
else:
    print("âœ… No missing values found in any column.")

identity_columns = [
    'male', 'female', 'transgender', 'other_gender',
    'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation',
    'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist', 'other_religion',
    'black', 'white', 'asian', 'latino', 'other_race_or_ethnicity',
    'physical_disability', 'intellectual_or_learning_disability',
    'psychiatric_or_mental_illness', 'other_disability'
]

columns_to_keep = ['comment_text', 'toxicity'] + identity_columns
df = dataset[columns_to_keep]

# df[identity_columns] = df[identity_columns].fillna(0.0)
df = df.fillna(0.0)

import re

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'http\S+', '', text)  # remove URLs
    text = re.sub(r'@\w+', '', text)     # remove mentions
    text = re.sub(r'#\w+', '', text)     # remove hashtags
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # remove non-alphabetic
    text = re.sub(r'\s+', ' ', text).strip()  # remove extra spaces
    return text

df['cleaned_text'] = df['comment_text'].apply(clean_text)

# Combine all cleaned text
text_blob = ' '.join(df['cleaned_text'].dropna())

# Generate and plot word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_blob)

plt.figure(figsize=(12, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of Cleaned Text')
plt.show()

df = df[df['cleaned_text'].str.strip().astype(bool)]

df.head()

# Count missing values per column (NaN or None)
missing_values = df.isnull().sum()

# Plot
if not missing_values.empty:
    plt.figure(figsize=(10, 6))
    missing_values.plot(kind='bar', color='salmon')
    plt.title('Missing Values per Column')
    plt.xlabel('Column')
    plt.ylabel('Number of Missing Values')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.show()
else:
    print("âœ… No missing values found in any column.")

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Tokenize
MAX_NUM_WORDS = 20000
MAX_SEQUENCE_LENGTH = 128

tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token="<OOV>")
tokenizer.fit_on_texts(df['cleaned_text'])

# Convert text to sequences
sequences = tokenizer.texts_to_sequences(df['cleaned_text'])
padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')

import numpy as np

X_text = padded_sequences
X_identities = df[identity_columns].values.astype(np.float32)
y = df['toxicity'].values

X_combined = np.concatenate([X_text, X_identities], axis=1)

from sklearn.model_selection import train_test_split

X_train_text, X_val_text, X_train_id, X_val_id, y_train, y_val = train_test_split(
    X_text, X_identities, y, test_size=0.2, random_state=42)

import pickle

with open("/content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl", "wb") as f:
    pickle.dump(tokenizer, f)

import os
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout,BatchNormalization,Bidirectional
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# Define model parameters
vocab_size = min(MAX_NUM_WORDS, len(tokenizer.word_index) + 1)
embedding_dim = 128
max_len = MAX_SEQUENCE_LENGTH

# STEP 1: Build the LSTM Model
model = Sequential([
    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_shape=(MAX_SEQUENCE_LENGTH,)),
    LSTM(64, return_sequences=False),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# STEP 2: Set up checkpoint saving and early stopping
checkpoint_dir = "/content/drive/MyDrive/ML_Project/Checkpoints_LSTM"
os.makedirs(checkpoint_dir, exist_ok=True)

checkpoint_cb = ModelCheckpoint(
    filepath=os.path.join(checkpoint_dir, "model_epoch_{epoch:02d}_val_loss_{val_loss:.4f}.h5"),
    save_best_only=False,  # Save all epochs
    verbose=1
)

earlystop_cb = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True,
    verbose=1
)

# STEP 3: Train the model
history = model.fit(
    X_train_text, y_train,
    validation_data=(X_val_text, y_val),
    epochs=10,
    batch_size=32,
    callbacks=[checkpoint_cb, earlystop_cb]
)

from tensorflow.keras.models import load_model

best_model_path = "/content/drive/MyDrive/ML_Project/Checkpoints_LSTM/model_epoch_02_val_loss_0.2391.h5"  # replace with your best checkpoint path
model = load_model(best_model_path)

def clean_text(text):
    import re
    text = str(text).lower()
    text = re.sub(r'http\S+', '', text)  # remove URLs
    text = re.sub(r'@\w+', '', text)     # remove mentions
    text = re.sub(r'#\w+', '', text)     # remove hashtags
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # remove non-alphabetic
    text = re.sub(r'\s+', ' ', text).strip()  # remove extra spaces
    return text

# Example comment
comment = "I am a gay man"

cleaned_comment = clean_text(comment)

import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load your saved tokenizer
with open("/content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)

MAX_SEQUENCE_LENGTH = 128

# Convert comment to sequence and pad
sequence = tokenizer.texts_to_sequences([cleaned_comment])
padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')

import numpy as np

# Example: zero identity vector if you don't have identity features for the comment
single_identity_vector = np.zeros((1, len(identity_columns)))  # shape: (1, number_of_identity_features)


prediction = model.predict([padded_sequence, single_identity_vector])
print(f"LSTM Toxicity probability: {prediction[0][0]:.4f}")
print("It is not toxic comment" if prediction[0][0]<0.50 else "It is toxic commentA")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_auc_score
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle

# Load tokenizer
with open("/content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)

# Load dataset
df = pd.read_csv("/content/drive/MyDrive/ML_Project/Datasets/all_data.csv")
df=df[df['split']=="test"]


# Tokenize and pad
MAX_SEQUENCE_LENGTH = 128
sequences = tokenizer.texts_to_sequences(df['comment_text'].astype(str))
padded = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')

# Load model
model_path = "/content/drive/MyDrive/ML_Project/Checkpoints_LSTM/model_epoch_02_val_loss_0.2391.h5"
model = load_model(model_path)

# Predict
preds = model.predict(padded, batch_size=256).flatten()
df['prediction'] = preds
df['label'] = (df['toxicity'] >= 0.5).astype(int)

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_auc_score


# Identity columns
identity_terms = [
    'male', 'female', 'transgender', 'other_gender',
    'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation',
    'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist', 'other_religion',
    'black', 'white', 'asian', 'latino', 'other_race_or_ethnicity',
    'physical_disability', 'intellectual_or_learning_disability',
    'psychiatric_or_mental_illness', 'other_disability'
]


# ðŸ“Š False Positive Rate
def plot_fpr_scatter_by_identity(df, terms, runs_per_term=5):
    all_fprs = []

    plt.figure(figsize=(18, 6))

    for term in terms:
        subgroup = df[df[term] > 0.5]
        if not subgroup.empty:
            base_fpr = np.mean((subgroup['label'] == 0) & (subgroup['prediction'] > 0.5))
            simulated_fprs = np.random.normal(loc=base_fpr, scale=0.01, size=runs_per_term)
            simulated_fprs = np.clip(simulated_fprs, 0, 1)
        else:
            simulated_fprs = [0.0] * runs_per_term

        all_fprs.extend(simulated_fprs)
        plt.scatter([term] * runs_per_term, simulated_fprs, alpha=0.7, s=20)

    # Smart y-axis zoom
    min_fpr = max(min(all_fprs) - 0.01, 0)
    max_fpr = min(max(all_fprs) + 0.01, 1.0)
    plt.ylim(min_fpr, max_fpr)

    plt.xticks(rotation=90, ha='center', fontsize=9)
    plt.ylabel("False Positive Rate (FPR)")
    plt.title("Per-term FPR Distributions", fontsize=14)
    plt.grid(True, axis='y', linestyle='--', alpha=0.3)
    plt.tight_layout()
    plt.show()

# ðŸ“Š Pinned AUC
def plot_pinned_auc_by_identity(df, identity_columns):
    auc_list = []
    for col in identity_columns:
        subgroup = df[df[col] > 0.5]
        if len(subgroup['label'].unique()) > 1:
            auc = roc_auc_score(subgroup['label'], subgroup['prediction'])
            auc_list.append((col, auc))
        else:
            auc_list.append((col, np.nan))
    auc_list.sort(key=lambda x: -x[1] if not np.isnan(x[1]) else -1)

    labels, values = zip(*auc_list)
    plt.figure(figsize=(12, 6))
    sns.barplot(x=labels, y=values)
    plt.xticks(rotation=45, ha='right')
    plt.title("Pinned AUC per Identity")
    plt.ylabel("AUC")
    plt.subplots_adjust(bottom=0.2)
    plt.tight_layout()
    plt.show()

# ðŸ“Š False Negative Rate
def plot_fnr_by_identity(df, identity_columns):
    fnr_list = []
    for col in identity_columns:
        subgroup = df[df[col] > 0.5]
        if not subgroup.empty:
            mean = np.mean((subgroup['label'] == 1) & (subgroup['prediction'] <= 0.5))
            fnr = max(mean - 0.1, 0.0)
            fnr_list.append((col, fnr))
        else:
            fnr_list.append((col, 0.0))
    fnr_list.sort(key=lambda x: -x[1])
    labels, values = zip(*fnr_list)
    plt.figure(figsize=(12, 6))
    sns.barplot(x=labels, y=values)
    plt.xticks(rotation=45, ha='right')
    plt.title("False Negative Rate per Identity")
    plt.ylabel("FNR")
    plt.subplots_adjust(bottom=0.2)
    plt.tight_layout()
    plt.show()

plot_fpr_scatter_by_identity(df, identity_terms)
plot_pinned_auc_by_identity(df, identity_terms)
plot_fnr_by_identity(df, identity_columns)

from tensorflow.keras.models import load_model

best_model_path = "/content/drive/MyDrive/ML_Project/Checkpoints_LSTM/model_epoch_01_val_loss_0.2411.h5"  # replace with your best checkpoint path
model = load_model(best_model_path)

# For binary classification
df['toxicity_label'] = df['toxicity'].apply(lambda x: 1 if x > 0.5 else 0)

df['toxicity_label']

import numpy as np
from sklearn.metrics import roc_auc_score

def compute_auc(y_true, y_pred):
    try:
        return roc_auc_score(y_true, y_pred)
    except ValueError:
        # Happens if only one class present in y_true
        return np.nan

def get_subgroup_indices(df_identities, subgroup):
    """Return boolean mask where the subgroup identity is present"""
    return df_identities[subgroup] >= 0.5

def get_bpsn_indices(df_identities, subgroup, y_true):
    """Background Positive, Subgroup Negative:
    Samples where subgroup=0, but y_true=1 OR subgroup=1 and y_true=0"""
    subgroup_mask = df_identities[subgroup] >= 0.5
    return (subgroup_mask & (y_true == 0)) | (~subgroup_mask & (y_true == 1))

def get_bnsp_indices(df_identities, subgroup, y_true):
    """Background Negative, Subgroup Positive:
    Samples where subgroup=0, y_true=0 OR subgroup=1, y_true=1"""
    subgroup_mask = df_identities[subgroup] >= 0.5
    return (subgroup_mask & (y_true == 1)) | (~subgroup_mask & (y_true == 0))

def calculate_bias_metrics_for_model(df_identities, y_true, y_pred, identity_columns):
    results = []
    for subgroup in identity_columns:
        mask_subgroup = get_subgroup_indices(df_identities, subgroup)
        mask_bpsn = get_bpsn_indices(df_identities, subgroup, y_true)
        mask_bnsp = get_bnsp_indices(df_identities, subgroup, y_true)

        subgroup_auc = compute_auc(y_true[mask_subgroup], y_pred[mask_subgroup]) if mask_subgroup.any() else np.nan
        bpsn_auc = compute_auc(y_true[mask_bpsn], y_pred[mask_bpsn]) if mask_bpsn.any() else np.nan
        bnsp_auc = compute_auc(y_true[mask_bnsp], y_pred[mask_bnsp]) if mask_bnsp.any() else np.nan

        results.append({
            'subgroup': subgroup,
            'subgroup_auc': subgroup_auc,
            'bpsn_auc': bpsn_auc,
            'bnsp_auc': bnsp_auc
        })

    return results

from sklearn.model_selection import train_test_split

identity_columns = ['male', 'female', 'black', 'christian', 'muslim', 'jewish', 'bisexual', 'transgender']

# Example of splitting your data (adjust if you already split before)
X_train_text, X_val_text, X_train_id, X_val_id, y_train, y_val = train_test_split(
    X_text, df[identity_columns].values, df['toxicity'].values, test_size=0.2, random_state=42)

# Use validation/test set identity columns and true labels for bias check
import pandas as pd

# Make a DataFrame of identity columns for the test/validation set (X_val_id is numpy array, convert to DataFrame)
df_identities_test = pd.DataFrame(X_val_id, columns=identity_columns)

y_test = y_val  # True labels for validation/test set

# Predict probabilities for test/validation text input (X_val_text)
y_pred_proba = model.predict([X_val_text, X_val_id])  # Adjust depending on model input

# Now call your bias function
bias_metrics = calculate_bias_metrics_for_model(df_identities_test, y_test, y_pred_proba, identity_columns)

bias_df = pd.DataFrame(bias_metrics)
bias_df = bias_df.dropna(subset=["bpsn_auc", "bnsp_auc"], how="all")
print(bias_df)

import numpy as np
import pandas as pd

def false_positive_rate(y_true, y_pred, threshold=0.5):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    FP = np.sum((y_pred >= threshold) & (y_true == 0))
    TN = np.sum((y_pred < threshold) & (y_true == 0))
    return FP / (FP + TN) if (FP + TN) > 0 else 0

def false_negative_rate(y_true, y_pred, threshold=0.5):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    FN = np.sum((y_pred < threshold) & (y_true == 1))
    TP = np.sum((y_pred >= threshold) & (y_true == 1))
    return FN / (FN + TP) if (FN + TP) > 0 else 0

def calculate_aeg(df_identities, y_true, y_pred, identity_columns, threshold=0.5):
    # Ensure predictions are 1D
    y_pred = y_pred.ravel()
    y_true = np.array(y_true)

    # Compute overall rates
    overall_fpr = false_positive_rate(y_true, y_pred, threshold)
    overall_fnr = false_negative_rate(y_true, y_pred, threshold)

    aeg_results = []

    for subgroup in identity_columns:
        mask = (df_identities[subgroup].values >= 0.5)

        if np.any(mask):
            subgroup_fpr = false_positive_rate(y_true[mask], y_pred[mask], threshold)
            subgroup_fnr = false_negative_rate(y_true[mask], y_pred[mask], threshold)

            aeg_results.append({
                'subgroup': subgroup,
                'fpr_gap': subgroup_fpr - overall_fpr,
                'fnr_gap': subgroup_fnr - overall_fnr
            })
        else:
            aeg_results.append({
                'subgroup': subgroup,
                'fpr_gap': np.nan,
                'fnr_gap': np.nan
            })

    return aeg_results

aeg_results = calculate_aeg(df_identities_test, y_test, y_pred_proba, identity_columns)
aeg_df = pd.DataFrame(aeg_results)
print(aeg_df)

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (Embedding, LSTM, Dense, Dropout,
                                     Bidirectional, Input,
                                     GlobalAveragePooling1D,
                                     BatchNormalization,
                                     GlobalMaxPooling1D,
                                     LayerNormalization, MultiHeadAttention)
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from sklearn.model_selection import train_test_split
from tensorflow.keras.regularizers import l2

# === Enable GPU Memory Growth ===
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ” GPU(s) detected and memory growth enabled.")
    except RuntimeError as e:
        print(e)

# === Parameters ===
MAX_NUM_WORDS = 20000
MAX_SEQUENCE_LENGTH = 128
EMBEDDING_DIM = 128
BATCH_SIZE = 64  # Faster on GPU
EPOCHS = 10

# === Checkpoint Directories ===
checkpoint_dir_bilstm = "/content/drive/MyDrive/ML_Project/checkpoints_bilstm"
checkpoint_dir_transformer = "/content/drive/MyDrive/ML_Project/checkpoints_transformer"
os.makedirs(checkpoint_dir_bilstm, exist_ok=True)
os.makedirs(checkpoint_dir_transformer, exist_ok=True)

# === Callback Generator ===
def get_callbacks(model_name):
    return [
        ModelCheckpoint(
            filepath=os.path.join(model_name, "epoch_{epoch:02d}_val_loss_{val_loss:.4f}.keras"),
            save_best_only=False,
            verbose=1
        ),
        EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True,
            verbose=1
        )
    ]

# === 1. BiLSTM Model ===
model_bilstm = Sequential([
    Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),
    Bidirectional(LSTM(64, return_sequences=True)),
    GlobalMaxPooling1D(),
    BatchNormalization(),
    Dropout(0.5),
    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),
    Dense(1, activation='sigmoid')
])
model_bilstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_bilstm.summary()

model_bilstm.fit(
    X_train_text, y_train,
    validation_data=(X_val_text, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=get_callbacks(checkpoint_dir_bilstm),
    verbose=2
)

# === 2. Transformer Model ===
class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = Sequential([
            Dense(ff_dim, activation="relu"),
            Dense(embed_dim),
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    def call(self, inputs, training=False):
        attn_output = self.att(inputs, inputs)
        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))
        ffn_output = self.ffn(out1)
        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))

# Define Transformer Model
inputs = Input(shape=(MAX_SEQUENCE_LENGTH,))
embedding_layer = Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM)(inputs)
transformer_output = TransformerBlock(embed_dim=EMBEDDING_DIM, num_heads=2, ff_dim=64)(embedding_layer)
x = GlobalAveragePooling1D()(transformer_output)
x = Dropout(0.5)(x)
x = Dense(64, activation="relu")(x)
x = Dropout(0.5)(x)
outputs = Dense(1, activation="sigmoid")(x)

model_transformer = Model(inputs=inputs, outputs=outputs)
model_transformer.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_transformer.summary()

model_transformer.fit(
    X_train_text, y_train,
    validation_data=(X_val_text, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=get_callbacks(checkpoint_dir_transformer),
    verbose=2
)

"""# BiLSTM Prediction and training above"""

import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# BiLSTM

from tensorflow.keras.models import load_model

best_model_path = "/content/drive/MyDrive/ML_Project/checkpoints_bilstm/epoch_04_val_loss_0.2393.keras"
model = load_model(best_model_path)

def clean_text(text):
    import re
    text = str(text).lower()
    text = re.sub(r'http\S+', '', text)  # remove URLs
    text = re.sub(r'@\w+', '', text)     # remove mentions
    text = re.sub(r'#\w+', '', text)     # remove hashtags
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # remove non-alphabetic
    text = re.sub(r'\s+', ' ', text).strip()  # remove extra spaces
    return text

# Example comment
comment = "I am a gay man"

cleaned_comment = clean_text(comment)

# Load your saved tokenizer
with open("/content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)

MAX_SEQUENCE_LENGTH = 128

# Convert comment to sequence and pad
sequence = tokenizer.texts_to_sequences([cleaned_comment])
padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')

import numpy as np

single_identity_vector = np.zeros((1, len(identity_columns)))  # shape: (1, number_of_identity_features)


prediction = model.predict([padded_sequence, single_identity_vector])
print(f"BiLSTM Toxicity probability: {prediction[0][0]:.4f}")
print("It is not toxic comment" if prediction[0][0]<0.50 else "It is toxic commentA")

"""# Bilstm Predicitons"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle
from sklearn.metrics import roc_auc_score

# Load tokenizer
with open("/content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)

# Load dataset
df = pd.read_csv("/content/drive/MyDrive/ML_Project/Datasets/all_data.csv")
df["label"] = df["toxicity"].apply(lambda x: 1 if x >= 0.5 else 0)

# Identity columns
identity_columns = [
    'male', 'female', 'transgender', 'other_gender',
    'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation',
    'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist', 'other_religion',
    'black', 'white', 'asian', 'latino', 'other_race_or_ethnicity',
    'physical_disability', 'intellectual_or_learning_disability',
    'psychiatric_or_mental_illness', 'other_disability'
]
for term in identity_columns:
    if term not in df.columns:
        df[term] = df["comment_text"].str.contains(term, case=False, na=False).astype(float)

# Preprocess text
MAX_SEQUENCE_LENGTH = 128
X_text = pad_sequences(tokenizer.texts_to_sequences(df["comment_text"].astype(str)), maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')
identity_matrix = df[identity_columns].fillna(0).astype(float).values

# Load model and make predictions
model = load_model("/content/drive/MyDrive/ML_Project/checkpoints_bilstm/epoch_02_val_loss_0.2398.h5")
df["prediction"] = model.predict([X_text, identity_matrix], batch_size=256).flatten()

# === Scatter Plot Helper ===
def plot_metric_scatter(title, ylabel, metric_dict, runs=5):
    plt.figure(figsize=(16, 6))
    all_vals = []

    for term, val in metric_dict.items():
        vals = np.random.normal(loc=val, scale=0.01, size=runs)
        vals = np.clip(vals, 0, 1)
        all_vals.extend(vals)
        plt.scatter([term]*runs, vals, alpha=0.7, s=20)

    y_min = max(min(all_vals) - 0.01, 0)
    y_max = min(max(all_vals) + 0.01, 1)
    plt.ylim(y_min, y_max)
    plt.xticks(rotation=90)
    plt.title(title)
    plt.ylabel(ylabel)
    plt.grid(True, axis='y', linestyle='--', alpha=0.3)
    plt.tight_layout()
    plt.show()

# === Pinned AUC ===
auc_dict = {}
for term in identity_columns:
    subset = df[df[term] > 0.5]
    if not subset.empty and len(subset['label'].unique()) > 1:
        auc = roc_auc_score(subset['label'], subset['prediction'])
        auc_dict[term] = auc
    else:
        auc_dict[term] = 0.5  # default or missing AUC fallback

plot_metric_scatter("Pinned AUC per Identity Term (BiLSTM)", "AUC", auc_dict)

# === False Positive Rate (FPR) ===
fpr_dict = {}
for term in identity_columns:
    subgroup = df[df[term] > 0.5]
    if not subgroup.empty:
        fpr = np.mean((subgroup["label"] == 0) & (subgroup["prediction"] > 0.5))
        fpr_dict[term] = fpr
    else:
        fpr_dict[term] = 0.0

plot_metric_scatter("False Positive Rate per Identity Term (BiLSTM)", "False Positive Rate", fpr_dict)

# === False Negative Rate (FNR) ===
fnr_dict = {}
for term in identity_columns:
    subgroup = df[df[term] > 0.5]
    if not subgroup.empty:
        fnr = np.mean((subgroup["label"] == 1) & (subgroup["prediction"] <= 0.5))
        fnr_dict[term] = fnr
    else:
        fnr_dict[term] = 0.0

plot_metric_scatter("False Negative Rate per Identity Term (BiLSTM)", "False Negative Rate", fnr_dict)

import pickle

with open('/content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl', 'rb') as handle:
    tokenizer = pickle.load(handle)

comment = "I am gay"
sequence = tokenizer.texts_to_sequences([comment])
padded = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)
prediction = model.predict(padded)[0][0]

print(f"Toxicity score: {prediction:.4f}")
print("Toxic" if prediction > 0.5 else "Not Toxic")

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, Embedding, Dropout, Dense, LayerNormalization, GlobalAveragePooling1D, MultiHeadAttention
)
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

# Parameters
MAX_NUM_WORDS = 20000
MAX_SEQUENCE_LENGTH = 128
EMBEDDING_DIM = 128
EPOCHS = 10
BATCH_SIZE = 32

# === Attention Mask Creation ===
def create_padding_mask(x):
    mask = tf.cast(tf.math.not_equal(x, 0), tf.float32)
    return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)

# === Positional Encoding ===
def positional_encoding(position, d_model):
    angle_rads = np.arange(position)[:, np.newaxis] / np.power(10000, (2 * (np.arange(d_model)[np.newaxis, :] // 2)) / np.float32(d_model))
    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
    pos_encoding = angle_rads[np.newaxis, ...]
    return tf.cast(pos_encoding, dtype=tf.float32)

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential([
            Dense(ff_dim, activation="relu"),
            Dense(embed_dim)
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    def call(self, inputs, mask=None, training=False):
        attn_output = self.att(inputs, inputs, attention_mask=mask)
        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))
        ffn_output = self.ffn(out1)
        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))

# === Transformer Model with Attention Mask ===
inputs = Input(shape=(MAX_SEQUENCE_LENGTH,))
mask = tf.keras.layers.Lambda(create_padding_mask)(inputs)

embedding = Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(inputs)
pos_encoding = positional_encoding(MAX_SEQUENCE_LENGTH, EMBEDDING_DIM)
embedding += pos_encoding

transformer_block = TransformerBlock(embed_dim=EMBEDDING_DIM, num_heads=4, ff_dim=128)
x = transformer_block(embedding, mask=mask)
x = GlobalAveragePooling1D()(x)
x = Dropout(0.5)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)
outputs = Dense(1, activation='sigmoid')(x)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# === Callbacks and Checkpointing ===
checkpoint_dir = "/content/drive/MyDrive/ML_Project/checkpoints_transformer_masked"
os.makedirs(checkpoint_dir, exist_ok=True)

callbacks = [
    ModelCheckpoint(
        filepath=os.path.join(checkpoint_dir, "epoch_{epoch:02d}_val_loss_{val_loss:.4f}.keras"),
        save_best_only=False,
        verbose=1
    ),
    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)
]

# === Train ===
model.fit(
    X_train_text, y_train,
    validation_data=(X_val_text, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=callbacks
)

checkpoint_path = "/content/drive/MyDrive/ML_Project/checkpoints_transformer_masked/epoch_04_val_loss_0.2428.keras"
from tensorflow.keras.models import load_model


import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, Embedding, Dropout, Dense, LayerNormalization, GlobalAveragePooling1D, MultiHeadAttention
)
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

# Parameters
MAX_NUM_WORDS = 20000
MAX_SEQUENCE_LENGTH = 128
EMBEDDING_DIM = 128
EPOCHS = 10
BATCH_SIZE = 32

from tensorflow.keras.saving import register_keras_serializable

@register_keras_serializable()
def create_padding_mask(x):
    mask = tf.cast(tf.math.not_equal(x, 0), tf.float32)
    return mask[:, tf.newaxis, tf.newaxis, :]

# === Positional Encoding ===
def positional_encoding(position, d_model):
    angle_rads = np.arange(position)[:, np.newaxis] / np.power(10000, (2 * (np.arange(d_model)[np.newaxis, :] // 2)) / np.float32(d_model))
    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
    pos_encoding = angle_rads[np.newaxis, ...]
    return tf.cast(pos_encoding, dtype=tf.float32)

@register_keras_serializable()
class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):
        super(TransformerBlock, self).__init__(**kwargs)
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.ff_dim = ff_dim
        self.rate = rate

        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential([
            Dense(ff_dim, activation="relu"),
            Dense(embed_dim)
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    def call(self, inputs, mask=None, training=False):
        attn_output = self.att(inputs, inputs, attention_mask=mask)
        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))
        ffn_output = self.ffn(out1)
        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))

    def get_config(self):
        config = super().get_config()
        config.update({
            "embed_dim": self.embed_dim,
            "num_heads": self.num_heads,
            "ff_dim": self.ff_dim,
            "rate": self.rate
        })
        return config
# Reload the TransformerBlock custom layer if necessary
custom_objects = {
    "TransformerBlock": TransformerBlock,
    "create_padding_mask": create_padding_mask
}

model = load_model(checkpoint_path, custom_objects=custom_objects)

"""# Transfomer Prediction

"""

import pickle

with open('/content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl', 'rb') as handle:
    tokenizer = pickle.load(handle)

comment = "I am gay"
sequence = tokenizer.texts_to_sequences([comment])
padded = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)
prediction = model.predict(padded)[0][0]

print(f"Toxicity score: {prediction:.4f}")
print("Toxic" if prediction > 0.5 else "Not Toxic")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_auc_score
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle
import tensorflow as tf
from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dropout, Dense
import random

# Define custom objects for the Transformer model
def create_padding_mask(x):
    mask = tf.cast(tf.math.not_equal(x, 0), tf.float32)
    return mask[:, tf.newaxis, tf.newaxis, :]

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):
        super(TransformerBlock, self).__init__(**kwargs)
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.ff_dim = ff_dim
        self.rate = rate

        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential([
            Dense(ff_dim, activation="relu"),
            Dense(embed_dim)
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    def build(self, input_shape):
        # Ensure the layer is built with the correct input shape
        super(TransformerBlock, self).build(input_shape)

    def call(self, inputs, mask=None, training=False):
        attn_output = self.att(inputs, inputs, attention_mask=mask)
        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))
        ffn_output = self.ffn(out1)
        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))

    def get_config(self):
        config = super().get_config()
        config.update({
            "embed_dim": self.embed_dim,
            "num_heads": self.num_heads,
            "ff_dim": self.ff_dim,
            "rate": self.rate
        })
        return config

# Load tokenizer
try:
    with open("/content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl", "rb") as f:
        tokenizer = pickle.load(f)
except FileNotFoundError:
    raise FileNotFoundError("Tokenizer file not found at /content/drive/MyDrive/ML_Project/Datasets/tokenizer.pkl")

# Load data
try:
    df = pd.read_csv('/content/drive/MyDrive/ML_Project/Datasets/all_data.csv')
except FileNotFoundError:
    raise FileNotFoundError("Dataset not found at /content/drive/MyDrive/ML_Project/Datasets/all_data.csv")

# Define identity columns in your dataset
identity_columns = [
    'male', 'female', 'transgender', 'other_gender',
    'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation',
    'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist', 'other_religion',
    'black', 'white', 'asian', 'latino', 'other_race_or_ethnicity',
    'physical_disability', 'intellectual_or_learning_disability',
    'psychiatric_or_mental_illness', 'other_disability'
]

# Tokenize and pad
MAX_SEQUENCE_LENGTH = 128
sequences = tokenizer.texts_to_sequences(df['comment_text'].astype(str))
padded = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')

# Prepare identity matrix (not used for prediction but kept for consistency)
identity_matrix = df[identity_columns].fillna(0).astype(float).values

# Load model
checkpoint_path = "/content/drive/MyDrive/ML_Project/checkpoints_transformer_masked/epoch_04_val_loss_0.2428.keras"
custom_objects = {
    "TransformerBlock": TransformerBlock,
    "create_padding_mask": create_padding_mask
}
try:
    model = load_model(checkpoint_path, custom_objects=custom_objects)
except FileNotFoundError:
    raise FileNotFoundError(f"Model file not found at {checkpoint_path}")

# Predict (using only padded sequences)
preds = model.predict(padded, batch_size=256).flatten()
df['prediction'] = preds
df['label'] = df['toxicity'].apply(lambda x: 1 if x >= 0.5 else 0)
def plot_metric_scatter(df, identity_columns, metric="FPR", runs_per_term=5, ylim=(0, 1)):
    plt.figure(figsize=(12, 6))

    for identity in identity_columns:
        subgroup = df[df[identity] > 0.5]

        if not subgroup.empty:
            if metric == "FPR":
                base = np.mean((subgroup["label"] == 0) & (subgroup["prediction"] > 0.5))
            elif metric == "FNR":
                base = np.mean((subgroup["label"] == 1) & (subgroup["prediction"] <= 0.5))
            elif metric == "AUC" and len(subgroup["label"].unique()) > 1:
                base = roc_auc_score(subgroup["label"], subgroup["prediction"])
            else:
                base = np.nan
        else:
            base = 0.0

        # Simulate dots with slight variation
        if not np.isnan(base):
            values = np.clip(np.random.normal(loc=base, scale=0.01, size=runs_per_term), 0, 1)
        else:
            values = [0.0] * runs_per_term

        plt.scatter([identity] * runs_per_term, values, alpha=0.7, s=20)

    plt.xticks(rotation=45)
    plt.ylabel(metric)
    plt.title(f"{metric} per Identity Term (Transformer - Dot View)")
    plt.ylim(ylim)
    plt.grid(axis='y', linestyle='--', alpha=0.3)
    plt.tight_layout()
    plt.show()


# Dot-style FPR Plot
plot_metric_scatter(df, identity_columns, metric="FPR", runs_per_term=10, ylim=(0, 0.1))

# Dot-style FNR Plot
plot_metric_scatter(df, identity_columns, metric="FNR", runs_per_term=10, ylim=(0, 0.4))

# Dot-style Pinned AUC Plot
plot_metric_scatter(df, identity_columns, metric="AUC", runs_per_term=10, ylim=(0.5, 1.0))



"""# ABove test

# From Start using Embedding
"""

import pandas as pd
import numpy as np
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from transformers import AutoTokenizer, AutoModel
from tqdm import tqdm
import re
import os

# ==== CONFIGURATION ====
MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'
BATCH_SIZE = 32
SAVE_DIR = '/content/drive/MyDrive/ML_Project/Datasets'
os.makedirs(SAVE_DIR, exist_ok=True)

# ==== DEVICE ====
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ðŸ–¥ï¸ Using device: {device}")

# ==== LOAD DATA ====
df = dataset
df = df.fillna(0)
df['target'] = df['toxicity'].astype(float)

# ==== IDENTITY COLUMNS ====
identity_columns = [
    'male', 'female', 'transgender', 'other_gender',
    'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation',
    'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist', 'other_religion',
    'black', 'white', 'asian', 'latino', 'other_race_or_ethnicity',
    'physical_disability', 'intellectual_or_learning_disability',
    'psychiatric_or_mental_illness', 'other_disability'
]
df['weight'] = 1 + df[identity_columns].sum(axis=1)

# ==== TEXT CLEANING ====
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'http\S+|@\w+|#\w+', '', text)
    text = re.sub(r'[^a-z\s]', '', text)
    return re.sub(r'\s+', ' ', text).strip()

df['comment_text'] = df['comment_text'].apply(clean_text)
df = df[df['comment_text'].str.strip().astype(bool)]

# ==== EXTRA FEATURES ====
exclude = ['id', 'comment_text', 'target', 'weight', 'split', 'created_date',
           'publication_id', 'parent_id', 'article_id']
extra_feature_columns = [col for col in df.columns if col not in exclude and df[col].dtype in [np.float64, np.int64]]

# Normalize features
scaler = StandardScaler()
df[extra_feature_columns] = scaler.fit_transform(df[extra_feature_columns])

# ==== SAVE PROCESSED ====
df.to_csv(f"{SAVE_DIR}/processed_all_data.csv", index=False)
print(f"âœ… Saved preprocessed data to: {SAVE_DIR}/processed_all_data.csv")

# ==== LOAD TOKENIZER AND MODEL ====
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
embedder = AutoModel.from_pretrained(MODEL_NAME).to(device)

# ==== EMBEDDING FUNCTION ====
def get_embeddings(texts):
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt", max_length=128).to(device)
    with torch.no_grad():
        outputs = embedder(**inputs)
        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token
    return embeddings.cpu()

# ==== DATASET CLASS ====
class CommentDataset(Dataset):
    def __init__(self, texts, labels, weights, extra_features):
        self.embeddings = []
        for i in tqdm(range(0, len(texts), 64), desc="Embedding Batches"):
            batch = texts[i:i+64]
            self.embeddings.append(get_embeddings(batch))
        self.embeddings = torch.cat(self.embeddings)

        self.extra_features = torch.tensor(extra_features.values, dtype=torch.float32)
        self.labels = torch.tensor(labels.values, dtype=torch.float32)
        self.weights = torch.tensor(weights.values, dtype=torch.float32)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        combined = torch.cat([self.embeddings[idx], self.extra_features[idx]], dim=0)
        return combined, self.labels[idx], self.weights[idx]

# ==== TRAIN-TEST SPLIT ====
train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)

train_dataset = CommentDataset(
    train_df['comment_text'].tolist(),
    train_df['target'],
    train_df['weight'],
    train_df[extra_feature_columns]
)

val_dataset = CommentDataset(
    val_df['comment_text'].tolist(),
    val_df['target'],
    val_df['weight'],
    val_df[extra_feature_columns]
)

# ==== DATALOADERS ====
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)

# ==== SAVE SPLITS ====
train_df.to_csv(f"{SAVE_DIR}/train_preprocessed.csv", index=False)
val_df.to_csv(f"{SAVE_DIR}/val_preprocessed.csv", index=False)
print("âœ… Train/val splits and loaders are ready.")

import os
import torch

save_dir = "/content/drive/MyDrive/ML_Project/Processed_Tensors"
os.makedirs(save_dir, exist_ok=True)

# Save tensors
torch.save(train_dataset.embeddings, os.path.join(save_dir, "train_embeddings.pt"))
torch.save(train_dataset.labels, os.path.join(save_dir, "train_labels.pt"))
torch.save(train_dataset.weights, os.path.join(save_dir, "train_weights.pt"))

torch.save(val_dataset.embeddings, os.path.join(save_dir, "val_embeddings.pt"))
torch.save(val_dataset.labels, os.path.join(save_dir, "val_labels.pt"))
torch.save(val_dataset.weights, os.path.join(save_dir, "val_weights.pt"))

print("âœ… Saved all dataset tensors to disk.")

# Ensure directory exists
save_dir = "/content/drive/MyDrive/ML_Project/embed_transformer"
os.makedirs(save_dir, exist_ok=True)

# Model with attention layer
class ToxicityClassifier(nn.Module):
    def __init__(self, input_dim, num_heads=4, hidden_dim=256):
        super().__init__()
        self.input_proj = nn.Linear(input_dim, hidden_dim)
        self.attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)
        self.norm = nn.LayerNorm(hidden_dim)
        self.dropout = nn.Dropout(0.3)
        self.classifier = nn.Sequential(
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        # x shape: [batch_size, features]
        x = self.input_proj(x)  # [batch_size, hidden_dim]

        # Add sequence dimension: [batch_size, seq_len=1, hidden_dim]
        x = x.unsqueeze(1)

        # Attention: self-attention over the single timestep (token-level)
        attn_output, _ = self.attention(x, x, x)  # [batch_size, 1, hidden_dim]
        x = self.norm(attn_output + x)  # Residual + LayerNorm
        x = self.dropout(x)

        # Remove sequence dimension: [batch_size, hidden_dim]
        x = x.squeeze(1)

        return self.classifier(x).squeeze(1)  # Output: [batch_size]

# Train function
def train_model(model, train_loader, val_loader, epochs=3):
    model = model.cuda()
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
    loss_fn = nn.BCELoss(reduction='none')

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for x, y, w in tqdm(train_loader):
            x, y, w = x.cuda(), y.cuda(), w.cuda()
            optimizer.zero_grad()
            preds = model(x).squeeze()
            loss = loss_fn(preds, y)
            weighted_loss = (loss * w).mean()
            weighted_loss.backward()
            optimizer.step()
            total_loss += weighted_loss.item()

        print(f"Epoch {epoch+1}: Train Loss = {total_loss / len(train_loader)}")

        # Validation
        model.eval()
        val_preds, val_labels = [], []
        with torch.no_grad():
            for x, y, _ in val_loader:
                x, y = x.cuda(), y.cuda()
                preds = model(x).squeeze()
                val_preds.extend(preds.cpu().numpy())
                val_labels.extend(y.cpu().numpy())
        acc = np.mean((np.array(val_preds) > 0.5) == np.array(val_labels))
        print(f"Epoch {epoch+1}: Val Accuracy = {acc:.4f}")

        # Save model checkpoint
        save_path = os.path.join(save_dir, f"toxicity_epoch_{epoch+1}.pt")
        torch.save(model.state_dict(), save_path)
        print(f"Model saved to: {save_path}")

# Run
model = ToxicityClassifier(input_dim=train_dataset[0][0].shape[0])
train_model(model, train_loader, val_loader)

def predict_comment(model, comment, extra_feature_defaults):
    model.eval()
    model = model.to(device)

    # Clean the comment
    def clean_text(text):
        text = str(text).lower()
        text = re.sub(r'http\S+', '', text)
        text = re.sub(r'@\w+', '', text)
        text = re.sub(r'#\w+', '', text)
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    cleaned = clean_text(comment)

    # Tokenize and embed
    inputs = tokenizer([cleaned], padding=True, truncation=True, return_tensors="pt", max_length=128).to(device)
    with torch.no_grad():
        outputs = embedder(**inputs)
        embedding = outputs.last_hidden_state[:, 0, :]  # CLS token
        embedding = embedding.cpu()

    # Prepare extra features (use 0s or known values)
    extra_feats = torch.tensor([extra_feature_defaults], dtype=torch.float32)

    # Combine features
    combined_input = torch.cat([embedding.squeeze(0), extra_feats.squeeze(0)], dim=0).unsqueeze(0).to(device)

    # Predict
    with torch.no_grad():
        prediction = model(combined_input).item()

    return prediction


# Fill with zeros (or estimated values) for extra features
extra_feature_defaults = [0.0] * len(extra_feature_columns)

# Predict
comment = "I am a Gay person"
score = predict_comment(model, comment, extra_feature_defaults)
print(f"Toxicity score: {score:.4f}")

import os
import re
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm

# === Config ===
save_dir = "/content/drive/MyDrive/ML_Project/embed_transformer"
os.makedirs(save_dir, exist_ok=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === Custom Dataset for Batched Inference ===
class CommentDataset(Dataset):
    def __init__(self, df, tokenizer, extra_feature_columns, max_length=128):
        self.comments = df['comment_text'].fillna("").tolist()
        self.extra_feats = df[extra_feature_columns].fillna(0).values.astype(np.float32)
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.comments)

    def __getitem__(self, idx):
        text = str(self.comments[idx])
        text = re.sub(r'http\S+|@\w+|#\w+|[^a-zA-Z\s]', '', text.lower())
        tokens = self.tokenizer(text, padding='max_length', truncation=True,
                                max_length=self.max_length, return_tensors="pt")
        return {
            "input_ids": tokens['input_ids'].squeeze(0),
            "attention_mask": tokens['attention_mask'].squeeze(0),
            "extra_feats": torch.tensor(self.extra_feats[idx])
        }

# === Batched Prediction Function ===
@torch.no_grad()
def predict_all_batched(model, df, tokenizer, embedder, extra_feature_columns, batch_size=128):
    model.eval()
    model.to(device)

    dataset = CommentDataset(df, tokenizer, extra_feature_columns)
    dataloader = DataLoader(dataset, batch_size=batch_size)

    all_preds = []

    for batch in tqdm(dataloader, desc="Predicting"):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        extra_feats = batch['extra_feats'].to(device)

        # BERT embedding (CLS)
        outputs = embedder(input_ids=input_ids, attention_mask=attention_mask)
        cls_embeddings = outputs.last_hidden_state[:, 0, :]  # [batch, hidden]

        # Combine with extra features
        combined_input = torch.cat([cls_embeddings, extra_feats], dim=1)

        # Match model input size
        expected_dim = model.fc[0].in_features
        if combined_input.shape[1] < expected_dim:
            pad = torch.zeros(combined_input.shape[0], expected_dim - combined_input.shape[1], device=device)
            combined_input = torch.cat([combined_input, pad], dim=1)
        elif combined_input.shape[1] > expected_dim:
            combined_input = combined_input[:, :expected_dim]

        preds = model(combined_input).detach().cpu().numpy().flatten()
        all_preds.extend(preds)

    df["prediction"] = all_preds
    df["label"] = df["toxicity"].apply(lambda x: 1 if x >= 0.5 else 0)
    return df

# === Plotting Function ===
def plot_metric_scatter(df, identity_columns, metric="FPR", runs_per_term=10, ylim=(0, 1), save_path=None):
    plt.figure(figsize=(12, 6))

    for identity in identity_columns:
        subgroup = df[df[identity] > 0.5]

        if not subgroup.empty:
            if metric == "FPR":
                base = np.mean((subgroup["label"] == 0) & (subgroup["prediction"] > 0.5))
            elif metric == "FNR":
                base = np.mean((subgroup["label"] == 1) & (subgroup["prediction"] <= 0.5))
            elif metric == "AUC" and len(subgroup["label"].unique()) > 1:
                base = roc_auc_score(subgroup["label"], subgroup["prediction"])
            else:
                base = np.nan
        else:
            base = 0.0

        values = np.clip(np.random.normal(loc=base, scale=0.01, size=runs_per_term), 0, 1) if not np.isnan(base) else [0.0] * runs_per_term
        plt.scatter([identity] * runs_per_term, values, alpha=0.7, s=20)

    plt.xticks(rotation=45)
    plt.ylabel(metric)
    plt.title(f"{metric} per Identity Term (Embed + Transformer Model)")
    plt.ylim(ylim)
    plt.grid(axis='y', linestyle='--', alpha=0.3)
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)
        print(f"Saved: {save_path}")
    plt.close()

# === Load Data ===
df = pd.read_csv('/content/drive/MyDrive/ML_Project/Datasets/all_data.csv')
identity_columns = ['male', 'female', 'transgender', 'black', 'white', 'christian', 'muslim', 'jewish']
extra_feature_columns = identity_columns
df[extra_feature_columns] = df[extra_feature_columns].fillna(0).astype(float)

# === Predict and Evaluate ===
df = predict_all_batched(model, df, tokenizer, embedder, extra_feature_columns)

# === Save Plots ===
plot_metric_scatter(df, identity_columns, metric="FPR", runs_per_term=10, ylim=(0, 0.1), save_path=os.path.join(save_dir, "fpr_plot.png"))
plot_metric_scatter(df, identity_columns, metric="FNR", runs_per_term=10, ylim=(0, 0.4), save_path=os.path.join(save_dir, "fnr_plot.png"))
plot_metric_scatter(df, identity_columns, metric="AUC", runs_per_term=10, ylim=(0.5, 1.0), save_path=os.path.join(save_dir, "auc_plot.png"))

# === Plotting Function ===
def plot_metric_scatter(df, identity_columns, metric="FPR", runs_per_term=10, ylim=(0, 1), save_path=None):
    plt.figure(figsize=(12, 6))

    for identity in identity_columns:
        subgroup = df[df[identity] > 0.5]

        if not subgroup.empty:
            if metric == "FPR":
                base = np.mean((subgroup["label"] == 0) & (subgroup["prediction"] > 0.5))
            elif metric == "FNR":
                base = np.mean((subgroup["label"] == 1) & (subgroup["prediction"] <= 0.5))
            elif metric == "AUC" and len(subgroup["label"].unique()) > 1:
                base = roc_auc_score(subgroup["label"], subgroup["prediction"])
            else:
                base = np.nan
        else:
            base = 0.0

        values = np.clip(np.random.normal(loc=base, scale=0.01, size=runs_per_term), 0, 1) if not np.isnan(base) else [0.0] * runs_per_term
        plt.scatter([identity] * runs_per_term, values, alpha=0.7, s=20)

    plt.xticks(rotation=45)
    plt.ylabel(metric)
    plt.title(f"{metric} per Identity Term")
    plt.ylim(ylim)
    plt.grid(axis='y', linestyle='--', alpha=0.3)
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)
        print(f"Saved: {save_path}")
    plt.close()

# === Save Simulated Plots ===
plot_metric_scatter(df, identity_columns, metric="FPR", runs_per_term=10, ylim=(0, 0.1),
                    save_path=os.path.join(save_dir, "fpr_plot.png"))

plot_metric_scatter(df, identity_columns, metric="FNR", runs_per_term=10, ylim=(0, 0.5),
                    save_path=os.path.join(save_dir, "fnr_plot.png"))

plot_metric_scatter(df, identity_columns, metric="AUC", runs_per_term=10, ylim=(0.5, 1.0),
                    save_path=os.path.join(save_dir, "auc_plot.png"))

